# Scraper スクリプトテンプレート指示

> **読み込み条件**: type === "scraper" の場合
> **対応ランタイム**: Python, Node.js

---

## 目的

Webページからデータを抽出するスクリプトを生成する。

---

## AIへの実装指示

### 必須機能

1. **ページ取得**
   - HTTPリクエストによるHTML取得
   - 動的コンテンツ対応（ヘッドレスブラウザ使用時）
   - User-Agent設定

2. **データ抽出**
   - CSSセレクタまたはXPathによる要素選択
   - テキスト、属性、リンクの抽出
   - ページネーション対応

3. **レート制限**
   - リクエスト間隔の制御
   - robots.txtの尊重（オプション）

4. **出力**
   - JSON/CSV形式での出力
   - 増分更新対応

### 推奨依存関係

| ランタイム | 推奨パッケージ |
|------------|----------------|
| Python | beautifulsoup4, lxml, httpx, playwright（動的） |
| Node.js | cheerio, puppeteer（動的） |

### 環境変数

- `{{TARGET_URL}}`: スクレイピング対象URL
- `{{REQUEST_DELAY}}`: リクエスト間隔（ミリ秒）
- `{{USER_AGENT}}`: カスタムUser-Agent

### 引数仕様

| 引数 | 必須 | 説明 |
|------|------|------|
| --url | ○ | 対象URL |
| --selector | ○ | 抽出対象のセレクタ |
| --output | × | 出力ファイルパス |
| --format | × | 出力形式（json/csv） |
| --dynamic | × | 動的コンテンツモード |

### 出力形式

- 抽出データをJSON配列または CSV形式で出力

---

## コード構造の指示

AIは以下の構造でコードを生成してください:

```
1. インポート
   - HTTPクライアント
   - パーサーライブラリ
   - 出力フォーマッター

2. 設定
   - デフォルト値
   - 終了コード定数

3. ユーティリティ関数
   - fetchPage(): ページ取得
   - parseHTML(): HTML解析
   - extractData(): データ抽出
   - formatOutput(): 出力整形

4. メイン処理
   - 引数パース
   - ページ取得
   - データ抽出
   - 結果出力
```

---

## 品質基準

AIは以下の基準を満たすコードを生成してください:

- [ ] リクエスト間隔の遵守
- [ ] エラー時のグレースフル終了
- [ ] 部分的な結果の保存
- [ ] メモリ効率の考慮（大量データ時）
- [ ] 適切なタイムアウト設定
